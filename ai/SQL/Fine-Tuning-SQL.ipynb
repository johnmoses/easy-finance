{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning for SQL to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 08:21:23.168657: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "from transformers import TextDataset, T5ForConditionalGeneration\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n",
      "4.44.0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "print(datasets.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name='google/flan-t5-small'\n",
    "model_name='t5-small'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "base_model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load integrated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_csql_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:8000]')\n",
    "dataset_csql_test = load_dataset(\"b-mc2/sql-create-context\", split='train[-2000:-1000]')\n",
    "dataset_csql_validation = load_dataset(\"b-mc2/sql-create-context\", split='train[-1000:]')\n",
    "\n",
    "dataset_tsql_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:8000]')\n",
    "dataset_tsql_train = dataset_tsql_train.remove_columns(['source', 'text'])\n",
    "dataset_tsql_train = dataset_tsql_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "dataset_tsql_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-2000:-1000]')\n",
    "dataset_tsql_test  = dataset_tsql_test.remove_columns(['source', 'text'])\n",
    "dataset_tsql_test  = dataset_tsql_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "dataset_tsql_validation   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-1000:]')\n",
    "dataset_tsql_validation   = dataset_tsql_validation.remove_columns(['source', 'text'])\n",
    "dataset_tsql_validation   = dataset_tsql_validation.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7845b30411d471b98fa7e1b06801391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniforge3/envs/mforge39/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 1600\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_local_train = load_dataset('csv', split='train[:80%]', data_files={'local_merged.csv'})\n",
    "dataset_local_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_local_test = load_dataset('csv', split='train[-20%:-10%]', data_files={'local_merged.csv'})\n",
    "dataset_local_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_local_validation = load_dataset('csv', split='train[-10%:]', data_files={'local_merged.csv'})\n",
    "dataset_local_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_x = DatasetDict({\n",
    "#     'train': interleave_datasets([dataset_tsql_train, dataset_local_train]),\n",
    "#     'test': interleave_datasets([dataset_tsql_test, dataset_local_test]),\n",
    "#     'validation': interleave_datasets([dataset_tsql_validation, dataset_local_validation])\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_train, \n",
    "        dataset_tsql_train,\n",
    "        dataset_local_train\n",
    "        ]\n",
    "    )\n",
    "dataset_test_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_test, \n",
    "        dataset_tsql_test,\n",
    "        dataset_local_test\n",
    "        ]\n",
    "    )\n",
    "dataset_validation_merged = concatenate_datasets(\n",
    "    [\n",
    "        dataset_csql_validation, \n",
    "        dataset_tsql_validation,\n",
    "        dataset_local_validation\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save datasets in `.csv` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875d659b660e4a77842582aa0b437541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db277fd8bf014b10be326f2882d0ba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3102fce35b4c7f82b8d2b9c638a2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1293725"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_merged.to_csv('train_merged.csv', index=False)\n",
    "dataset_test_merged.to_csv('test_merged.csv', index=False)\n",
    "dataset_validation_merged.to_csv('validation_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 17600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 2200\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 2200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={\n",
    "    \"train\": \"train_merged.csv\", \n",
    "    \"test\": \"test_merged.csv\", \n",
    "    \"validation\": \"validation_merged.csv\"\n",
    "    })\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'CREATE TABLE table_name_94 (round VARCHAR, event VARCHAR)',\n",
       " 'question': 'Which round has pain and glory 2006 as the event?',\n",
       " 'answer': 'SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CREATE TABLE head (age INTEGER)</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>SELECT COUNT(*) FROM head WHERE age &gt; 56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CREATE TABLE head (name VARCHAR, born_state VA...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>SELECT name, born_state, age FROM head ORDER B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREATE TABLE department (creation VARCHAR, nam...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>SELECT creation, name, budget_in_billions FROM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CREATE TABLE department (budget_in_billions IN...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>SELECT MAX(budget_in_billions), MIN(budget_in_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CREATE TABLE department (num_employees INTEGER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>SELECT AVG(num_employees) FROM department WHER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0                    CREATE TABLE head (age INTEGER)   \n",
       "1  CREATE TABLE head (name VARCHAR, born_state VA...   \n",
       "2  CREATE TABLE department (creation VARCHAR, nam...   \n",
       "3  CREATE TABLE department (budget_in_billions IN...   \n",
       "4  CREATE TABLE department (num_employees INTEGER...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                              answer  \n",
       "0           SELECT COUNT(*) FROM head WHERE age > 56  \n",
       "1  SELECT name, born_state, age FROM head ORDER B...  \n",
       "2  SELECT creation, name, budget_in_billions FROM...  \n",
       "3  SELECT MAX(budget_in_billions), MIN(budget_in_...  \n",
       "4  SELECT AVG(num_employees) FROM department WHER...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('./train_merged.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAT_ML_TEMPLATE = \"\"\"\n",
    "# {% for message in messages %}\n",
    "#     {% if message['role'] == 'user' %}\n",
    "#         {{'<|im_start|>user\\n' + message['content'].strip() + '<|im_end|>' }}\n",
    "#     {% elif message['role'] == 'system' %}\n",
    "#         {{'<|im_start|>system\\n' + message['content'].strip() + '<|im_end|>' }}\n",
    "#     {% elif message['role'] == 'assistant' %}\n",
    "#         {{'<|im_start|>assistant\\n'  + message['content'] + '<|im_end|>' }}\n",
    "#     {% endif %}\n",
    "# {% endfor %}\n",
    "# \"\"\"\n",
    "\n",
    "# ASSISTANT_PROMPT = \"<|im_start|>assistant\\n\"\n",
    "\n",
    "# EOS_TOKEN = \"<|im_end|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, eos_token=\"<|im_end|>\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.chat_template = CHAT_ML_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = \"Tables:\\n\"\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
    "\n",
    "    data_zip = zip(example['context'], example['question'])\n",
    "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 17600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 2200\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 2200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['question','context','answer'])\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with zero shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Tables:\n",
      "CREATE TABLE table_name_94 (round VARCHAR, event VARCHAR)\n",
      "\n",
      "Question:\n",
      "Which round has pain and glory 2006 as the event?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Question: Which round has pain and glory 2006 as the event? Answer: Which round has pain and glory 2006 as the event?\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs = inputs.to('cpu')\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    base_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_sql(query):\n",
    "    input_text = \"translate English to SQL: %s \" % query\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = base_model.generate(input_ids)\n",
    "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query: Welche Runde hat Schmerz und Ruhm 2006 als Veranstaltung?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"Which round has pain and glory 2006 as the event?\"\n",
    "output = translate_to_sql(question)\n",
    "print(\"SQL Query:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(query):\n",
    "    input_text = f'translate English to SQL: {query}'\n",
    "    features = tokenizer([input_text], return_tensors='pt').to(device)\n",
    "    output = base_model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features['attention_mask'],\n",
    "        max_new_tokens=200\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welche Runde hat Schmerz und Ruhm 2006 als Veranstaltung?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which round has pain and glory 2006 as the event?\"\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which round has pain and glory 2006 as the event?\n",
      "Predict. :Welche Runde hat Schmerz und Ruhm 2006 als Veranstaltung?\n",
      "Expected: SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"\n",
      "=================================\n",
      "\n",
      "Question: Which record has john flemming as the opponent?\n",
      "Predict. :SQL-Record hat john flemming als Gegner?\n",
      "Expected: SELECT record FROM table_name_14 WHERE opponent = \"john flemming\"\n",
      "=================================\n",
      "\n",
      "Question: Which record has 5:00 as the time, jess liaudin as the opponent for the location of england?\n",
      "Predict. :SQL hat 5:00 als Zeit, jess liaudin als Gegner für die Lage der england?\n",
      "Expected: SELECT record FROM table_name_49 WHERE time = \"5:00\" AND opponent = \"jess liaudin\" AND location = \"england\"\n",
      "=================================\n",
      "\n",
      "Question: Name the score for home of green bay packers\n",
      "Predict. :SQL - Name the score for home of green bay packers\n",
      "Expected: SELECT score FROM table_name_37 WHERE home = \"green bay packers\"\n",
      "=================================\n",
      "\n",
      "Question: Name the home for 21-17\n",
      "Predict. :Identifizieren Sie die Heimat für 21-17\n",
      "Expected: SELECT home FROM table_name_93 WHERE score = \"21-17\"\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print('Question: ' + dataset['test'][i]['question'])\n",
    "    print('Predict. :' + get_sql(dataset['test'][i]['question']))\n",
    "    print('Expected: ' + dataset['test'][i]['answer'])\n",
    "    print('=================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "finetuned_model = finetuned_model.to('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'training-t5'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-3,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,     # batch size per device during training\n",
    "    per_device_eval_batch_size=16,      # batch size for evaluation\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='steps',        # evaluation strategy to adopt during training\n",
    "    eval_steps=500,                  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167661b1e8e74eb888beb3511d9fb64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4413552284240723,\n",
       " 'eval_model_preparation_time': 0.002,\n",
       " 'eval_runtime': 84.4542,\n",
       " 'eval_samples_per_second': 26.05,\n",
       " 'eval_steps_per_second': 1.634}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82de152873a146a5a2fbd80af4551930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.418, 'grad_norm': 0.14278097450733185, 'learning_rate': 0.004886363636363637, 'epoch': 0.05}\n",
      "{'loss': 0.1458, 'grad_norm': 0.10544981807470322, 'learning_rate': 0.004772727272727273, 'epoch': 0.09}\n",
      "{'loss': 0.1129, 'grad_norm': 0.07779989391565323, 'learning_rate': 0.004659090909090909, 'epoch': 0.14}\n",
      "{'loss': 0.1045, 'grad_norm': 0.06239340826869011, 'learning_rate': 0.004545454545454545, 'epoch': 0.18}\n",
      "{'loss': 0.0967, 'grad_norm': 0.07310223579406738, 'learning_rate': 0.004431818181818182, 'epoch': 0.23}\n",
      "{'loss': 0.0687, 'grad_norm': 0.07015125453472137, 'learning_rate': 0.004318181818181818, 'epoch': 0.27}\n",
      "{'loss': 0.062, 'grad_norm': 0.1204940602183342, 'learning_rate': 0.004204545454545455, 'epoch': 0.32}\n",
      "{'loss': 0.0638, 'grad_norm': 0.05975992605090141, 'learning_rate': 0.004090909090909091, 'epoch': 0.36}\n",
      "{'loss': 0.0601, 'grad_norm': 0.06554871797561646, 'learning_rate': 0.003977272727272727, 'epoch': 0.41}\n",
      "{'loss': 0.061, 'grad_norm': 0.04516300559043884, 'learning_rate': 0.003863636363636364, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabf2803f1664447bc769545e53e7cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04569010064005852, 'eval_model_preparation_time': 0.002, 'eval_runtime': 84.6068, 'eval_samples_per_second': 26.003, 'eval_steps_per_second': 1.631, 'epoch': 0.45}\n",
      "{'loss': 0.0604, 'grad_norm': 0.06717697530984879, 'learning_rate': 0.00375, 'epoch': 0.5}\n",
      "{'loss': 0.0546, 'grad_norm': 0.08848704397678375, 'learning_rate': 0.0036363636363636364, 'epoch': 0.55}\n",
      "{'loss': 0.0562, 'grad_norm': 0.05489804595708847, 'learning_rate': 0.003522727272727273, 'epoch': 0.59}\n",
      "{'loss': 0.0603, 'grad_norm': 0.060955531895160675, 'learning_rate': 0.003409090909090909, 'epoch': 0.64}\n",
      "{'loss': 0.0538, 'grad_norm': 0.06508537381887436, 'learning_rate': 0.0032954545454545454, 'epoch': 0.68}\n",
      "{'loss': 0.0417, 'grad_norm': 0.07296702265739441, 'learning_rate': 0.003181818181818182, 'epoch': 0.73}\n",
      "{'loss': 0.0476, 'grad_norm': 0.062193285673856735, 'learning_rate': 0.0030681818181818184, 'epoch': 0.77}\n",
      "{'loss': 0.0449, 'grad_norm': 0.06822644174098969, 'learning_rate': 0.002954545454545455, 'epoch': 0.82}\n",
      "{'loss': 0.0462, 'grad_norm': 0.09813297539949417, 'learning_rate': 0.0028409090909090914, 'epoch': 0.86}\n",
      "{'loss': 0.0407, 'grad_norm': 0.07271239161491394, 'learning_rate': 0.002727272727272727, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422b88f4348d41c284d7faeb71828671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.035053450614213943, 'eval_model_preparation_time': 0.002, 'eval_runtime': 84.9366, 'eval_samples_per_second': 25.902, 'eval_steps_per_second': 1.625, 'epoch': 0.91}\n",
      "{'loss': 0.0378, 'grad_norm': 0.054241083562374115, 'learning_rate': 0.0026136363636363636, 'epoch': 0.95}\n",
      "{'loss': 0.0423, 'grad_norm': 0.0972590371966362, 'learning_rate': 0.0025, 'epoch': 1.0}\n",
      "{'loss': 0.0426, 'grad_norm': 0.052853044122457504, 'learning_rate': 0.0023863636363636366, 'epoch': 1.05}\n",
      "{'loss': 0.0338, 'grad_norm': 0.053635984659194946, 'learning_rate': 0.0022727272727272726, 'epoch': 1.09}\n",
      "{'loss': 0.0284, 'grad_norm': 0.04393618553876877, 'learning_rate': 0.002159090909090909, 'epoch': 1.14}\n",
      "{'loss': 0.0348, 'grad_norm': 0.04246603697538376, 'learning_rate': 0.0020454545454545456, 'epoch': 1.18}\n",
      "{'loss': 0.0328, 'grad_norm': 0.07602375000715256, 'learning_rate': 0.001931818181818182, 'epoch': 1.23}\n",
      "{'loss': 0.0317, 'grad_norm': 0.07025616616010666, 'learning_rate': 0.0018181818181818182, 'epoch': 1.27}\n",
      "{'loss': 0.0325, 'grad_norm': 0.044547151774168015, 'learning_rate': 0.0017045454545454545, 'epoch': 1.32}\n",
      "{'loss': 0.0303, 'grad_norm': 0.046929843723773956, 'learning_rate': 0.001590909090909091, 'epoch': 1.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d103038f5df24b4992af210dd14149ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02869999222457409, 'eval_model_preparation_time': 0.002, 'eval_runtime': 84.7172, 'eval_samples_per_second': 25.969, 'eval_steps_per_second': 1.629, 'epoch': 1.36}\n",
      "{'loss': 0.0284, 'grad_norm': 0.05072499439120293, 'learning_rate': 0.0014772727272727275, 'epoch': 1.41}\n",
      "{'loss': 0.035, 'grad_norm': 0.043536391109228134, 'learning_rate': 0.0013636363636363635, 'epoch': 1.45}\n",
      "{'loss': 0.0317, 'grad_norm': 0.033162590116262436, 'learning_rate': 0.00125, 'epoch': 1.5}\n",
      "{'loss': 0.03, 'grad_norm': 0.0664527639746666, 'learning_rate': 0.0011363636363636363, 'epoch': 1.55}\n",
      "{'loss': 0.0339, 'grad_norm': 0.03389521688222885, 'learning_rate': 0.0010227272727272728, 'epoch': 1.59}\n",
      "{'loss': 0.0254, 'grad_norm': 0.051419828087091446, 'learning_rate': 0.0009090909090909091, 'epoch': 1.64}\n",
      "{'loss': 0.0276, 'grad_norm': 0.054062169045209885, 'learning_rate': 0.0007954545454545455, 'epoch': 1.68}\n",
      "{'loss': 0.0256, 'grad_norm': 0.06520362943410873, 'learning_rate': 0.0006818181818181818, 'epoch': 1.73}\n",
      "{'loss': 0.0295, 'grad_norm': 0.03848317265510559, 'learning_rate': 0.0005681818181818182, 'epoch': 1.77}\n",
      "{'loss': 0.0295, 'grad_norm': 0.04420353099703789, 'learning_rate': 0.00045454545454545455, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75bac0a4f6f435f812f7ce0ffea8c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.024220574647188187, 'eval_model_preparation_time': 0.002, 'eval_runtime': 84.8041, 'eval_samples_per_second': 25.942, 'eval_steps_per_second': 1.627, 'epoch': 1.82}\n",
      "{'loss': 0.0238, 'grad_norm': 0.059269968420267105, 'learning_rate': 0.0003409090909090909, 'epoch': 1.86}\n",
      "{'loss': 0.0329, 'grad_norm': 0.036003947257995605, 'learning_rate': 0.00022727272727272727, 'epoch': 1.91}\n",
      "{'loss': 0.0222, 'grad_norm': 0.0551101379096508, 'learning_rate': 0.00011363636363636364, 'epoch': 1.95}\n",
      "{'loss': 0.0273, 'grad_norm': 0.11864445358514786, 'learning_rate': 0.0, 'epoch': 2.0}\n",
      "{'train_runtime': 7985.0875, 'train_samples_per_second': 4.408, 'train_steps_per_second': 0.276, 'train_loss': 0.05568295933983543, 'epoch': 2.0}\n",
      "CPU times: user 23min 13s, sys: 11min 52s, total: 35min 6s\n",
      "Wall time: 2h 13min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2200, training_loss=0.05568295933983543, metrics={'train_runtime': 7985.0875, 'train_samples_per_second': 4.408, 'train_steps_per_second': 0.276, 'total_flos': 4764031411814400.0, 'train_loss': 0.05568295933983543, 'epoch': 2.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.save_pretrained(\"model-t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-t5/tokenizer_config.json',\n",
       " 'model-t5/special_tokens_map.json',\n",
       " 'model-t5/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"model-t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model-t5\"\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test fine-tuned model with zero shot inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Tables:\n",
      "CREATE TABLE table_name_94 (round VARCHAR, event VARCHAR)\n",
      "\n",
      "Question:\n",
      "Which round has pain and glory 2006 as the event?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "FINE-TUNED MODEL - ZERO SHOT:\n",
      "SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "# index = len(dataset['test'])-100\n",
    "\n",
    "question = dataset['test'][index]['question']\n",
    "context = dataset['test'][index]['context']\n",
    "answer = dataset['test'][index]['answer']\n",
    "\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs = inputs.to('cpu')\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    finetuned_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(query):\n",
    "    prompt = \"translate English to SQL: %s \" % query\n",
    "    features = tokenizer([prompt], return_tensors='pt')\n",
    "    output = finetuned_model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        max_new_tokens=200\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT id FROM id WHERE SQL = \"johnmoses\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is my user id?\"\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which round has pain and glory 2006 as the event?\n",
      "Predict. :SELECT round FROM round WHERE event = \"Purple and glory 2006\"\n",
      "Expected: SELECT round FROM table_name_94 WHERE event = \"pain and glory 2006\"\n",
      "=================================\n",
      "\n",
      "Question: Which record has john flemming as the opponent?\n",
      "Predict. :SELECT record FROM record WHERE opponent = \"John flemming\"\n",
      "Expected: SELECT record FROM table_name_14 WHERE opponent = \"john flemming\"\n",
      "=================================\n",
      "\n",
      "Question: Which record has 5:00 as the time, jess liaudin as the opponent for the location of england?\n",
      "Predict. :SELECT record FROM record WHERE location = 5:00 AND location = 'england'\n",
      "Expected: SELECT record FROM table_name_49 WHERE time = \"5:00\" AND opponent = \"jess liaudin\" AND location = \"england\"\n",
      "=================================\n",
      "\n",
      "Question: Name the score for home of green bay packers\n",
      "Predict. :SELECT score FROM score WHERE home of green bay packers.yard_name = \"Home of Green Bay Packers\"\n",
      "Expected: SELECT score FROM table_name_37 WHERE home = \"green bay packers\"\n",
      "=================================\n",
      "\n",
      "Question: Name the home for 21-17\n",
      "Predict. :SELECT home FROM home WHERE 21-17\n",
      "Expected: SELECT home FROM table_name_93 WHERE score = \"21-17\"\n",
      "=================================\n",
      "\n",
      "Question: What engine did Scuderia Ambrosiana with fewer than 4 points have?\n",
      "Predict. :SELECT engine FROM Scuderia ambrosiana WHERE  4\n",
      "Expected: SELECT engine FROM table_name_85 WHERE entrant = \"scuderia ambrosiana\" AND points < 4\n",
      "=================================\n",
      "\n",
      "Question: What chassis had fewer than 0 points in a year before 1954?\n",
      "Predict. :SELECT chassis FROM chassis WHERE  0 AND a year  1954\n",
      "Expected: SELECT chassis FROM table_name_39 WHERE year < 1954 AND points = 0\n",
      "=================================\n",
      "\n",
      "Question: What chassis had an entrant of G.A. Vandervell?\n",
      "Predict. :SELECT chassis FROM chassis WHERE entrant = \"G.A. Vandervell\"\n",
      "Expected: SELECT chassis FROM table_name_5 WHERE entrant = \"g.a. vandervell\"\n",
      "=================================\n",
      "\n",
      "Question: How many people were in attendance on may 2?\n",
      "Predict. :SELECT COUNT(*) FROM people WHERE SQL = 2\n",
      "Expected: SELECT MIN(attendance) FROM table_name_3 WHERE date = \"may 2\"\n",
      "=================================\n",
      "\n",
      "Question: How many people were in attendance on may 17?\n",
      "Predict. :SELECT COUNT(*) FROM people WHERE SQL = 17\n",
      "Expected: SELECT MIN(attendance) FROM table_name_7 WHERE date = \"may 17\"\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10, 1):\n",
    "    print('Question: ' + dataset['test'][i]['question'])\n",
    "    print('Predict. :' + get_sql(dataset['test'][i]['question']))\n",
    "    print('Expected: ' + dataset['test'][i]['answer'])\n",
    "    print('=================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer\n",
    "from safetensors.torch import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "peft_model = peft_model.to('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, packing, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:195: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'training-peft-t5'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs= 3\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "    \n",
    "peft_trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset= tokenized_datasets['train'],\n",
    "    eval_dataset= tokenized_datasets['test'],\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=tokenizer.model_max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb7c715d8434111a436219772b437d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5420283079147339,\n",
       " 'eval_model_preparation_time': 0.004,\n",
       " 'eval_runtime': 93.2244,\n",
       " 'eval_samples_per_second': 23.599,\n",
       " 'eval_steps_per_second': 4.72}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfa2497cf2740d195db3b3ed49b00ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2879, 'grad_norm': 0.12263398617506027, 'learning_rate': 0.0009526515151515152, 'epoch': 0.14}\n",
      "{'loss': 0.1362, 'grad_norm': 0.10611046105623245, 'learning_rate': 0.0009053030303030303, 'epoch': 0.28}\n",
      "{'loss': 0.097, 'grad_norm': 0.1095716655254364, 'learning_rate': 0.0008579545454545454, 'epoch': 0.43}\n",
      "{'loss': 0.0925, 'grad_norm': 0.10936679691076279, 'learning_rate': 0.0008106060606060606, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d2035bba-0413-448d-9603-8159d86164ff)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0862, 'grad_norm': 0.081715889275074, 'learning_rate': 0.0007632575757575758, 'epoch': 0.71}\n",
      "{'loss': 0.0759, 'grad_norm': 0.10686590522527695, 'learning_rate': 0.0007159090909090909, 'epoch': 0.85}\n",
      "{'loss': 0.0677, 'grad_norm': 0.04453447088599205, 'learning_rate': 0.0006685606060606061, 'epoch': 0.99}\n",
      "{'loss': 0.0693, 'grad_norm': 0.15954449772834778, 'learning_rate': 0.0006212121212121212, 'epoch': 1.14}\n",
      "{'loss': 0.066, 'grad_norm': 0.06855412572622299, 'learning_rate': 0.0005738636363636364, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 18feed48-4139-4a31-b924-0129e95152d2)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0614, 'grad_norm': 0.055628933012485504, 'learning_rate': 0.0005265151515151515, 'epoch': 1.42}\n",
      "{'loss': 0.0672, 'grad_norm': 0.054170046001672745, 'learning_rate': 0.0004791666666666667, 'epoch': 1.56}\n",
      "{'loss': 0.0591, 'grad_norm': 0.032898057252168655, 'learning_rate': 0.0004318181818181818, 'epoch': 1.7}\n",
      "{'loss': 0.0581, 'grad_norm': 0.07897771149873734, 'learning_rate': 0.000384469696969697, 'epoch': 1.85}\n",
      "{'loss': 0.0563, 'grad_norm': 0.06949831545352936, 'learning_rate': 0.0003371212121212121, 'epoch': 1.99}\n",
      "{'loss': 0.0591, 'grad_norm': 0.06898975372314453, 'learning_rate': 0.0002897727272727273, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f846ae3b160>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: e5ae0324-35a8-455f-bff4-5a082f5eaa71)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0498, 'grad_norm': 0.06746852397918701, 'learning_rate': 0.00024242424242424245, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f846ae5ea90>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: a289ee59-805e-45c3-9ecd-a466f9845aab)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0511, 'grad_norm': 0.08892177790403366, 'learning_rate': 0.00019507575757575756, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f8418a49490>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: b6d5c75a-3f71-4853-934d-6ccff83fa010)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0558, 'grad_norm': 0.13726957142353058, 'learning_rate': 0.00014772727272727274, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f84b8d81f10>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 0626c8d9-48ec-429c-b4cd-32d20f190354)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0489, 'grad_norm': 0.07677163183689117, 'learning_rate': 0.00010037878787878788, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/other.py:619: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f8418a49340>: Failed to resolve \\'huggingface.co\\' ([Errno 8] nodename nor servname provided, or not known)\"))'), '(Request ID: 775c614f-621f-4072-8d36-e059e4c43856)') - silently ignoring the lookup for the file config.json in t5-small.\n",
      "  warnings.warn(\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/peft/utils/save_and_load.py:218: UserWarning: Could not find a config file in t5-small - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0466, 'grad_norm': 0.05929362773895264, 'learning_rate': 5.303030303030303e-05, 'epoch': 2.84}\n",
      "{'loss': 0.0545, 'grad_norm': 0.05964748188853264, 'learning_rate': 5.681818181818182e-06, 'epoch': 2.98}\n",
      "{'train_runtime': 21606.7415, 'train_samples_per_second': 2.444, 'train_steps_per_second': 0.489, 'train_loss': 0.07824968086047605, 'epoch': 3.0}\n",
      "CPU times: user 1h 12min 2s, sys: 5min 54s, total: 1h 17min 56s\n",
      "Wall time: 6h 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10560, training_loss=0.07824968086047605, metrics={'train_runtime': 21606.7415, 'train_samples_per_second': 2.444, 'train_steps_per_second': 0.489, 'total_flos': 7337387910758400.0, 'train_loss': 0.07824968086047605, 'epoch': 3.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-peft-t5/tokenizer_config.json',\n",
       " 'model-peft-t5/special_tokens_map.json',\n",
       " 'model-peft-t5/tokenizer.json')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.save_pretrained(\"model-peft-t5\")\n",
    "tokenizer.save_pretrained(\"model-peft-t5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(peft_model, \"peft_model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,179,648 || all params: 61,686,272 || trainable%: 1.9123\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(base_model, peft_config)\n",
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model-peft-t5 were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.0.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.0.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.0.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.1.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.1.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.1.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.1.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.2.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.2.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.2.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.2.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.3.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.3.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.3.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.3.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.4.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.4.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.4.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.4.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight', 'decoder.block.5.layer.0.SelfAttention.q.base_layer.weight', 'decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'decoder.block.5.layer.0.SelfAttention.v.base_layer.weight', 'decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight', 'decoder.block.5.layer.1.EncDecAttention.q.base_layer.weight', 'decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight', 'decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight', 'decoder.block.5.layer.1.EncDecAttention.v.base_layer.weight', 'decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight', 'decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight', 'encoder.block.0.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.0.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.1.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.1.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.2.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.2.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.3.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.3.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.4.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.4.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight', 'encoder.block.5.layer.0.SelfAttention.q.base_layer.weight', 'encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight', 'encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight', 'encoder.block.5.layer.0.SelfAttention.v.base_layer.weight', 'encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight', 'encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at ./model-peft-t5 and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "peft_model_path = \"./model-peft-t5\"\n",
    "peft_model = AutoModelForSeq2SeqLM.from_pretrained(peft_model_path)\n",
    "\n",
    "peft_tokenizer = AutoTokenizer.from_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peft_sql(query):\n",
    "    prompt = \"translate English to SQL: %s </s>\" % query\n",
    "    features = tokenizer([prompt], return_tensors='pt')\n",
    "    output = peft_model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features[\"attention_mask\"],\n",
    "        max_new_tokens=200\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True).replace(\"<pad> \", \"\", 1).replace(\"</s>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wie viele Treffen haben wir?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many meetings do we have?\"\n",
    "get_peft_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate quantitatively with ROUGE Metric\n",
    "Perform inferences for test dataset. Do 5 only, due to time it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = dataset['test'][0:20]['question']\n",
    "contexts = dataset['test'][0:20]['context']\n",
    "human_answers = dataset['test'][0:20]['answer']\n",
    "\n",
    "base_model_answers = []\n",
    "finetuned_model_answers = []\n",
    "peft_model_answers = []\n",
    "\n",
    "for idx, question in enumerate(questions):\n",
    "    prompt = f\"\"\"Tables:\n",
    "    {contexts[idx]}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    human_text_output = human_answers[idx]\n",
    "\n",
    "    base_model_outputs = base_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    base_model_output = tokenizer.decode(base_model_outputs[0], skip_special_tokens=True)\n",
    "    base_model_answers.append(base_model_output)\n",
    "\n",
    "    finetuned_model_outputs = finetuned_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    finetuned_model_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
    "    finetuned_model_answers.append(finetuned_model_output)\n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids,generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "    peft_model_answers.append(peft_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_answers</th>\n",
       "      <th>base_model</th>\n",
       "      <th>finetuned_model</th>\n",
       "      <th>peft_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT round FROM table_name_94 WHERE event = ...</td>\n",
       "      <td>Question: Which round has pain and glory 2006 ...</td>\n",
       "      <td>SELECT round FROM table_name_94 WHERE event = ...</td>\n",
       "      <td>Question: Which round has pain and glory 2006 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT record FROM table_name_14 WHERE opponen...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT record FROM table_name_14 WHERE opponen...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT record FROM table_name_49 WHERE time = ...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT record FROM table_name_49 WHERE locatio...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT score FROM table_name_37 WHERE home = \"...</td>\n",
       "      <td>Tables: CREATE TABLE table_name_37 (score VARC...</td>\n",
       "      <td>SELECT score FROM table_name_37 WHERE home = \"...</td>\n",
       "      <td>Tables: CREATE TABLE table_name_37 (score VARC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT home FROM table_name_93 WHERE score = \"...</td>\n",
       "      <td>Tables: CREATE TABLE table_name_93 (home VARCH...</td>\n",
       "      <td>SELECT home FROM table_name_93 WHERE score = 2...</td>\n",
       "      <td>Tables: CREATE TABLE table_name_93 (home VARCH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SELECT engine FROM table_name_85 WHERE entrant...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT engine FROM table_name_85 WHERE entrant...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SELECT chassis FROM table_name_39 WHERE year &lt;...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT chassis FROM table_name_39 WHERE year  ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SELECT chassis FROM table_name_5 WHERE entrant...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT chassis FROM table_name_5 WHERE entrant...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SELECT MIN(attendance) FROM table_name_3 WHERE...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT SUM(attendance) FROM table_name_3 WHERE...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT MIN(attendance) FROM table_name_7 WHERE...</td>\n",
       "      <td>Answer: How many people were in attendance on ...</td>\n",
       "      <td>SELECT SUM(attendance) FROM table_name_7 WHERE...</td>\n",
       "      <td>Answer: How many people were in attendance on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SELECT COUNT(weeks_on_chart__uk_) FROM table_n...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT COUNT(weeks_on_chart__uk_) FROM table_n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SELECT title FROM table_name_50 WHERE weeks_on...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT title FROM table_name_50 WHERE weeks_on...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SELECT COUNT(ects_credit_points) FROM table_na...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT COUNT(ects_credit_points) FROM table_na...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SELECT teaching_language FROM table_name_69 WH...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT teaching_language FROM table_name_69 WH...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELECT program FROM table_name_35 WHERE durati...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT program FROM table_name_35 WHERE durati...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SELECT teaching_language FROM table_name_51 WH...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT teaching_language FROM table_name_51 WH...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELECT engine FROM table_name_79 WHERE pts &gt; 0</td>\n",
       "      <td>Answer</td>\n",
       "      <td>SELECT engine FROM table_name_79 WHERE pts &gt; 0</td>\n",
       "      <td>Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SELECT AVG(pts) FROM table_name_44 WHERE engin...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT AVG(pts) FROM table_name_44 WHERE engin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SELECT SUM(against) FROM table_name_75 WHERE c...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT SUM(against) FROM table_name_75 WHERE c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SELECT SUM(against) FROM table_name_19 WHERE d...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT SUM(against) FROM table_name_19 WHERE d...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        human_answers  \\\n",
       "0   SELECT round FROM table_name_94 WHERE event = ...   \n",
       "1   SELECT record FROM table_name_14 WHERE opponen...   \n",
       "2   SELECT record FROM table_name_49 WHERE time = ...   \n",
       "3   SELECT score FROM table_name_37 WHERE home = \"...   \n",
       "4   SELECT home FROM table_name_93 WHERE score = \"...   \n",
       "5   SELECT engine FROM table_name_85 WHERE entrant...   \n",
       "6   SELECT chassis FROM table_name_39 WHERE year <...   \n",
       "7   SELECT chassis FROM table_name_5 WHERE entrant...   \n",
       "8   SELECT MIN(attendance) FROM table_name_3 WHERE...   \n",
       "9   SELECT MIN(attendance) FROM table_name_7 WHERE...   \n",
       "10  SELECT COUNT(weeks_on_chart__uk_) FROM table_n...   \n",
       "11  SELECT title FROM table_name_50 WHERE weeks_on...   \n",
       "12  SELECT COUNT(ects_credit_points) FROM table_na...   \n",
       "13  SELECT teaching_language FROM table_name_69 WH...   \n",
       "14  SELECT program FROM table_name_35 WHERE durati...   \n",
       "15  SELECT teaching_language FROM table_name_51 WH...   \n",
       "16     SELECT engine FROM table_name_79 WHERE pts > 0   \n",
       "17  SELECT AVG(pts) FROM table_name_44 WHERE engin...   \n",
       "18  SELECT SUM(against) FROM table_name_75 WHERE c...   \n",
       "19  SELECT SUM(against) FROM table_name_19 WHERE d...   \n",
       "\n",
       "                                           base_model  \\\n",
       "0   Question: Which round has pain and glory 2006 ...   \n",
       "1                                            Question   \n",
       "2                                                True   \n",
       "3   Tables: CREATE TABLE table_name_37 (score VARC...   \n",
       "4   Tables: CREATE TABLE table_name_93 (home VARCH...   \n",
       "5                                            Question   \n",
       "6                                                True   \n",
       "7                                            Question   \n",
       "8                                            Question   \n",
       "9   Answer: How many people were in attendance on ...   \n",
       "10                                               True   \n",
       "11                                               True   \n",
       "12                                           Question   \n",
       "13                                           Question   \n",
       "14                                           Question   \n",
       "15                                               True   \n",
       "16                                             Answer   \n",
       "17                                               True   \n",
       "18                                               True   \n",
       "19                                           Question   \n",
       "\n",
       "                                      finetuned_model  \\\n",
       "0   SELECT round FROM table_name_94 WHERE event = ...   \n",
       "1   SELECT record FROM table_name_14 WHERE opponen...   \n",
       "2   SELECT record FROM table_name_49 WHERE locatio...   \n",
       "3   SELECT score FROM table_name_37 WHERE home = \"...   \n",
       "4   SELECT home FROM table_name_93 WHERE score = 2...   \n",
       "5   SELECT engine FROM table_name_85 WHERE entrant...   \n",
       "6   SELECT chassis FROM table_name_39 WHERE year  ...   \n",
       "7   SELECT chassis FROM table_name_5 WHERE entrant...   \n",
       "8   SELECT SUM(attendance) FROM table_name_3 WHERE...   \n",
       "9   SELECT SUM(attendance) FROM table_name_7 WHERE...   \n",
       "10  SELECT COUNT(weeks_on_chart__uk_) FROM table_n...   \n",
       "11  SELECT title FROM table_name_50 WHERE weeks_on...   \n",
       "12  SELECT COUNT(ects_credit_points) FROM table_na...   \n",
       "13  SELECT teaching_language FROM table_name_69 WH...   \n",
       "14  SELECT program FROM table_name_35 WHERE durati...   \n",
       "15  SELECT teaching_language FROM table_name_51 WH...   \n",
       "16     SELECT engine FROM table_name_79 WHERE pts > 0   \n",
       "17  SELECT AVG(pts) FROM table_name_44 WHERE engin...   \n",
       "18  SELECT SUM(against) FROM table_name_75 WHERE c...   \n",
       "19  SELECT SUM(against) FROM table_name_19 WHERE d...   \n",
       "\n",
       "                                           peft_model  \n",
       "0   Question: Which round has pain and glory 2006 ...  \n",
       "1                                            Question  \n",
       "2                                                True  \n",
       "3   Tables: CREATE TABLE table_name_37 (score VARC...  \n",
       "4   Tables: CREATE TABLE table_name_93 (home VARCH...  \n",
       "5                                            Question  \n",
       "6                                                True  \n",
       "7                                            Question  \n",
       "8                                            Question  \n",
       "9   Answer: How many people were in attendance on ...  \n",
       "10                                               True  \n",
       "11                                               True  \n",
       "12                                           Question  \n",
       "13                                           Question  \n",
       "14                                           Question  \n",
       "15                                               True  \n",
       "16                                             Answer  \n",
       "17                                               True  \n",
       "18                                               True  \n",
       "19                                           Question  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_summaries = list(zip(human_answers, base_model_answers, finetuned_model_answers, peft_model_answers))\n",
    "df = pd.DataFrame(zipped_summaries, columns=['human_answers','base_model','finetuned_model','peft_model'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute ROUGE score for a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\n",
      " {'rouge1': 0.06086309523809523, 'rouge2': 0.029091312056737588, 'rougeL': 0.05803571428571428, 'rougeLsum': 0.060057773109243685}\n",
      "Fine-tuned model:\n",
      " {'rouge1': 0.9759720279720281, 'rouge2': 0.932786674844396, 'rougeL': 0.9612762237762238, 'rougeLsum': 0.9623723212271599}\n",
      "PEFT model:\n",
      " {'rouge1': 0.06086309523809523, 'rouge2': 0.029091312056737588, 'rougeL': 0.05803571428571428, 'rougeLsum': 0.060057773109243685}\n"
     ]
    }
   ],
   "source": [
    "# Load ROUGE\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "# Select dataset\n",
    "answers = dataset['test'][0:20]['answer']\n",
    "\n",
    "base_model_results = rouge.compute(\n",
    "    predictions=base_model_answers,\n",
    "    references=answers,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('Base Model:\\n',base_model_results)\n",
    "\n",
    "finetuned_model_results = rouge.compute(\n",
    "    predictions=finetuned_model_answers,\n",
    "    references=answers,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('Fine-tuned model:\\n',finetuned_model_results)\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_answers,\n",
    "    references=answers,\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('PEFT model:\\n',peft_model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mconda38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
