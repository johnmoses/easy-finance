{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collator with Bidirectional Encoder Representations from Transformers (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 17:35:49.530125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import missingno as msno\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from keras.preprocessing import text\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer,BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Is anyone there?', 'Hello', 'Good day', \"What's up\", 'whatsup', 'Hi there, can you help me with something?', 'Hello! I have a question. Can you assist me?', 'Hey, I need your help with something.', 'Good morning/afternoon/evening! Can you answer a question for me?', 'Greetings! I need your assistance with something.', 'Hi,can you provide me with some information?', 'Hello, can you help me with a task?', \"Hey,I'm looking for some guidance. Can you help?\", 'Good day! Can you assist me with a query?', 'Hi,I would like to ask you a question.', 'Hello', 'Greetings', 'Good morning', 'Good afternoon', 'Good evening', 'Salutations', 'Pleasure to chat with you', \"It's great to talk with you\", 'Hi chatbot', 'Hello chatbot', 'Hey chatbot', \"What's new\", \"How's it going\", \"What's happening\", 'What can you do for me', 'Can you help me', 'I need your help', 'I have a question', \"I'm here to chat\", \"Let's talk\"], 'responses': ['Hello!', 'Hi there, how can I help?', 'Greetings, how may i help you?', 'Good day, what brings you here?', 'Yo, what can I do for you?', 'Hey there, how may I assist you?', 'Welcome, what can I help you with?', 'Nice to meet you, how may I be of assistance?', 'Pleasure to chat with you, what can I do for you?', \"I'm a chatbot, how can I help you today?\", 'My name is [bot name], what can I do for you?', \"I'm here to help, what can I assist you with?\", \"What's up, how may I assist you today?\", 'Hi, how can I be of service?', 'Good to see you, what can I help you with?', 'Hi there, what brings you to me?', \"I'm here to answer your questions, what would you like to know?\", 'How may I be of assistance to you today?', 'Hi, what can I do for you today?', 'What can I help you with today?', \"I'm here to chat with you, what would you like to talk about?\", 'How may I assist you in solving your problem?', \"I'm here to assist you, what can I do for you today?\", 'Hi, how can I make your day better?', 'What can I do to assist you today?', \"I'm here to listen to you, what can I help you with?\", 'Hi there, how may I assist you with your inquiry?', \"I'm here to answer your questions, what would you like to know\", 'What can I help you with today?', \"I'm here to make your life easier, how can I assist you?\", 'How can I help you today?', \"I'm here to make things easier for you, what can I do for you?\", 'Hi, how can I assist you today?', \"What's on your mind, how may I assist you today?\", 'How may I assist you in resolving your issue?', \"I'm here to assist you, what can I do for you today?\", 'Hi there, what can I help you with?', 'How may I be of service to you today?', \"I'm here to assist you with your needs, what can I do for you?\", 'How can I make your day better today?', \"I'm here to make things easier for you, what can I help you with?\", 'Hi there, how may I assist you in solving your problem?', 'What can I help you with today', \"I'm here to help you out, what can I do for you?\", 'How may I be of assistance today?', \"I'm here to provide answers to your questions, what would you like to know?\", 'Hi, how can I help you today?', 'How may I assist you in achieving your goals?']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\", 'Okay'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'can_do', 'patterns': ['What can i get here?', 'What more can i do?', 'What else can i do?'], 'responses': ['Count attendance reports at locationid ', 'List attendance reports at location this month', 'Show attendance report']}, {'tag': 'attendance_count', 'patterns': ['Count attendance reports at locationid '], 'responses': ['Report:']}, {'tag': 'attendance_list', 'patterns': ['List attendance reports at locationid '], 'responses': ['Report:']}, {'tag': 'finance_count', 'patterns': ['Count financial reports at locationid '], 'responses': ['Report:']}, {'tag': 'finance_list', 'patterns': ['List financial reports at locationid '], 'responses': ['Report:']}, {'tag': 'testimony_count', 'patterns': ['Count testimony reports at locationid'], 'responses': ['Report:']}, {'tag': 'testimony_list', 'patterns': ['List testimony reports at locationid'], 'responses': ['Report:']}, {'tag': 'report_submission', 'patterns': ['report: locationid is, meetingid is, meetingdate is '], 'responses': ['God bless you for submitting your report', 'Good work! Thanks.', 'Thanks for submitting your report']}, {'tag': 'report_sample', 'patterns': ['Show me a report format', 'Is there an example of a report?', 'What is the pattern for reporting', 'Sample report', 'sample report'], 'responses': ['Report: locationid is 485, meetingid is 1, meetingdate is 2024/06/16, men are 2,  women are 3, youthboys are 4, youthgirls are 5, childrenboys are 6, childrengirls are 7, newcomers are 1, newconverts are 1.', 'Report: locationid is 485, meetingid is 1, meetingdate is 2024/06/16, slipnumber is 122, naira is 100, dollar is 10.', 'Report: locationid is 485, meetingid is 1, meetingdate is 2024/06/16, My testimony is how God saved me, I was a terrible sinner.', 'Report: locationid is 485, meetingid is 1, meetingdate is 2024/06/16, men are 2,  women are 3, youthboys are 4, youthgirls are 5, childrenboys are 6, childrengirls are 7, newcomers are 1,  newconverts are 1, slipnumber is 122, naira is 100, dollar is 10.', 'Report: locationid is 485, meetingid is 1, meetingdate is 2024/06/16, men are 2,  women are 3, youthboys are 4, youthgirls are 5, childrenboys are 6, childrengirls are 7, newcomers are 1,  newconverts are 1, slipnumber is 122, naira is 100. My testimony is this healing and deliverance.']}, {'tag': 'countrystate_list', 'patterns': ['List my Country/States', 'List my Country/States', 'List my country/states', 'List my Country States', 'List my country states', 'List my country/states', 'List my country-states'], 'responses': ['My Country/States:']}, {'tag': 'region_list', 'patterns': ['List my Regions', 'list my regions'], 'responses': ['My Regions:']}, {'tag': 'group_list', 'patterns': ['List my Groups', 'list my groups'], 'responses': ['My Groups:']}, {'tag': 'location_list', 'patterns': ['List my locations', 'list my locations'], 'responses': ['Locations:']}, {'tag': 'countrystate_show', 'patterns': ['show country/state with countrystateid ', 'show country-state with countrystateid'], 'responses': ['Country/state:']}, {'tag': 'region_show', 'patterns': ['Show region with regionid', 'show region regionid'], 'responses': ['Region:']}, {'tag': 'group_show', 'patterns': ['Show group with groupid', 'show group with groupid'], 'responses': ['Group:']}, {'tag': 'location_show', 'patterns': ['Show location with locationid', 'show location with locationid'], 'responses': ['Location:']}, {'tag': 'countrystate_admin_list', 'patterns': ['list country/state admins at countrystateid '], 'responses': ['Country/States admins:']}, {'tag': 'region_admin_list', 'patterns': ['list region admins at regionid'], 'responses': ['Region admins:']}, {'tag': 'group_admin_list', 'patterns': ['list group admins at groupid'], 'responses': ['Group admins:']}, {'tag': 'location_admin_list', 'patterns': ['list location admins at locationid'], 'responses': ['Location admins:']}, {'tag': 'countrystate_admin_add', 'patterns': ['add to country/state with countrystateid admin with userid'], 'responses': ['Adding Country/States admins...']}, {'tag': 'region_admin_add', 'patterns': ['add to region with regionid admin with userid '], 'responses': ['Adding Region admins...:']}, {'tag': 'group_admin_add', 'patterns': ['add to group with groupid admin with userid'], 'responses': ['Adding Group admins...']}, {'tag': 'location_admin_add', 'patterns': ['add to location with locationid admin with userid '], 'responses': ['Adding Location admins...']}, {'tag': 'countrystate_admin_remove', 'patterns': ['remove from country/state with countrystateid admin with userid'], 'responses': ['Removing Country/States admin...']}, {'tag': 'region_admin_remove', 'patterns': ['remove from region with regionid admin with userid'], 'responses': ['Removing Region admins...:']}, {'tag': 'group_admin_remove', 'patterns': ['remove from group with groupid admin with userid'], 'responses': ['Removing Group admin...']}, {'tag': 'location_admin_remove', 'patterns': ['remove from location with locationid admin with userid'], 'responses': ['Removing Location admin...']}, {'tag': 'meeting_list', 'patterns': ['list our meetings', 'what about meetings', 'list meeting and codes'], 'responses': ['Meetings:']}, {'tag': 'user_show', 'patterns': ['show my user information', 'show my user info'], 'responses': ['Your user info:']}, {'tag': 'user_signup', 'patterns': ['Sign me up:', 'I want to sign up', 'Can i signup', 'Register a new account', 'I want to create an account'], 'responses': [\"Let's start creating your new account!\"]}, {'tag': 'password_reset', 'patterns': ['I forgot my password:', 'reset or change my password?'], 'responses': [\"Let's recover it together!\"]}, {'tag': 'helpdesk', 'patterns': ['hlp:', 'Help desk', 'help info', 'help'], 'responses': ['Results:']}, {'tag': 'unrecognized_input', 'patterns': ['.*'], 'responses': ['Sorry, I cannot understand that, but I will take this query to improve my dataset.']}]}\n"
     ]
    }
   ],
   "source": [
    "def load_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        file=json.load(f)\n",
    "    return file   \n",
    "    \n",
    "filename=\"intents.json\"\n",
    "intents=load_json_file(filename)\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe for patterns and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Pattern, Tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df():\n",
    "    df=pd.DataFrame({'Pattern':[],'Tag':[]})\n",
    "    return df\n",
    "    \n",
    "df=create_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_info(json_file,df):\n",
    "    for intent in json_file['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            sentence_tag=[pattern,intent['tag']]\n",
    "            df.loc[len(df.index)] = sentence_tag\n",
    "    return df        \n",
    "df=extract_json_info(intents,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's up</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pattern       Tag\n",
       "0                Hi  greeting\n",
       "1  Is anyone there?  greeting\n",
       "2             Hello  greeting\n",
       "3          Good day  greeting\n",
       "4         What's up  greeting"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109 entries, 0 to 108\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Pattern  109 non-null    object\n",
      " 1   Tag      109 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 classes in or tags\n",
      "['greeting' 'thanks' 'goodbye' 'can_do' 'attendance_count'\n",
      " 'attendance_list' 'finance_count' 'finance_list' 'testimony_count'\n",
      " 'testimony_list' 'report_submission' 'report_sample' 'countrystate_list'\n",
      " 'region_list' 'group_list' 'location_list' 'countrystate_show'\n",
      " 'region_show' 'group_show' 'location_show' 'countrystate_admin_list'\n",
      " 'region_admin_list' 'group_admin_list' 'location_admin_list'\n",
      " 'countrystate_admin_add' 'region_admin_add' 'group_admin_add'\n",
      " 'location_admin_add' 'countrystate_admin_remove' 'region_admin_remove'\n",
      " 'group_admin_remove' 'location_admin_remove' 'meeting_list' 'user_show'\n",
      " 'user_signup' 'password_reset' 'helpdesk' 'unrecognized_input']\n"
     ]
    }
   ],
   "source": [
    "x=len(df['Tag'].unique())\n",
    "print(f\"{x} classes in or tags\")\n",
    "\n",
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pattern    0\n",
       "Tag        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Is', 'anyone', 'there?', 'Hello']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus(series):\n",
    "    words = []\n",
    "    for text in series:\n",
    "        for word in text.split():\n",
    "            words.append(word.strip())\n",
    "    return words\n",
    "\n",
    "corpus = get_corpus(df.Pattern)\n",
    "corpus[:5]\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('with', 31), ('my', 17), ('you', 14), ('List', 13), ('locationid', 12), ('a', 10), ('to', 10), ('at', 10), ('list', 9), ('me', 8)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'with': 31,\n",
       " 'my': 17,\n",
       " 'you': 14,\n",
       " 'List': 13,\n",
       " 'locationid': 12,\n",
       " 'a': 10,\n",
       " 'to': 10,\n",
       " 'at': 10,\n",
       " 'list': 9,\n",
       " 'me': 8}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(corpus)\n",
    "most_common = counter.most_common(10)\n",
    "print(most_common)\n",
    "most_common = dict(most_common)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_text_ngrams(corpus, n,g):\n",
    "    vec = CountVectorizer(ngram_range=(1, 1)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another dataframe for patterns, tags and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's up</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pattern       Tag\n",
       "0                Hi  greeting\n",
       "1  Is anyone there?  greeting\n",
       "2             Hello  greeting\n",
       "3          Good day  greeting\n",
       "4         What's up  greeting"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of unique tags as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting', 'thanks', 'goodbye', 'can_do', 'attendance_count']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=df2['Tag'].unique().tolist()\n",
    "labels=[s.strip() for s in labels]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `id` to `label` and vise versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label={id:label for id,label in enumerate(labels)}\n",
    "label2id={label:id for id,label in enumerate(labels)}\n",
    "num_labels=len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'greeting',\n",
       " 1: 'thanks',\n",
       " 2: 'goodbye',\n",
       " 3: 'can_do',\n",
       " 4: 'attendance_count',\n",
       " 5: 'attendance_list',\n",
       " 6: 'finance_count',\n",
       " 7: 'finance_list',\n",
       " 8: 'testimony_count',\n",
       " 9: 'testimony_list',\n",
       " 10: 'report_submission',\n",
       " 11: 'report_sample',\n",
       " 12: 'countrystate_list',\n",
       " 13: 'region_list',\n",
       " 14: 'group_list',\n",
       " 15: 'location_list',\n",
       " 16: 'countrystate_show',\n",
       " 17: 'region_show',\n",
       " 18: 'group_show',\n",
       " 19: 'location_show',\n",
       " 20: 'countrystate_admin_list',\n",
       " 21: 'region_admin_list',\n",
       " 22: 'group_admin_list',\n",
       " 23: 'location_admin_list',\n",
       " 24: 'countrystate_admin_add',\n",
       " 25: 'region_admin_add',\n",
       " 26: 'group_admin_add',\n",
       " 27: 'location_admin_add',\n",
       " 28: 'countrystate_admin_remove',\n",
       " 29: 'region_admin_remove',\n",
       " 30: 'group_admin_remove',\n",
       " 31: 'location_admin_remove',\n",
       " 32: 'meeting_list',\n",
       " 33: 'user_show',\n",
       " 34: 'user_signup',\n",
       " 35: 'password_reset',\n",
       " 36: 'helpdesk',\n",
       " 37: 'unrecognized_input'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greeting': 0,\n",
       " 'thanks': 1,\n",
       " 'goodbye': 2,\n",
       " 'can_do': 3,\n",
       " 'attendance_count': 4,\n",
       " 'attendance_list': 5,\n",
       " 'finance_count': 6,\n",
       " 'finance_list': 7,\n",
       " 'testimony_count': 8,\n",
       " 'testimony_list': 9,\n",
       " 'report_submission': 10,\n",
       " 'report_sample': 11,\n",
       " 'countrystate_list': 12,\n",
       " 'region_list': 13,\n",
       " 'group_list': 14,\n",
       " 'location_list': 15,\n",
       " 'countrystate_show': 16,\n",
       " 'region_show': 17,\n",
       " 'group_show': 18,\n",
       " 'location_show': 19,\n",
       " 'countrystate_admin_list': 20,\n",
       " 'region_admin_list': 21,\n",
       " 'group_admin_list': 22,\n",
       " 'location_admin_list': 23,\n",
       " 'countrystate_admin_add': 24,\n",
       " 'region_admin_add': 25,\n",
       " 'group_admin_add': 26,\n",
       " 'location_admin_add': 27,\n",
       " 'countrystate_admin_remove': 28,\n",
       " 'region_admin_remove': 29,\n",
       " 'group_admin_remove': 30,\n",
       " 'location_admin_remove': 31,\n",
       " 'meeting_list': 32,\n",
       " 'user_show': 33,\n",
       " 'user_signup': 34,\n",
       " 'password_reset': 35,\n",
       " 'helpdesk': 36,\n",
       " 'unrecognized_input': 37}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add converted `label2id` to df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's up</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pattern       Tag  labels\n",
       "0                Hi  greeting       0\n",
       "1  Is anyone there?  greeting       0\n",
       "2             Hello  greeting       0\n",
       "3          Good day  greeting       0\n",
       "4         What's up  greeting       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['labels'] = df2['Tag'].map(lambda x: label2id[x.strip()])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Is anyone there?', 'Hello', 'Good day', \"What's up\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=list(df2['Pattern'])\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=list(df2['labels'])\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bert-base-uncased\"\n",
    "max_len=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(model_name,max_length=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model=BertForSequenceClassification.from_pretrained(model_name,num_labels=num_labels,id2label=id2label,label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding=tokenizer(X_train,truncation=True,padding=True)\n",
    "test_encoding=tokenizer(X_test,truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = tokenizer(X, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, encodings, labels):\n",
    "        \n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_encoding, y_train)\n",
    "test_dataloader = DataLoader(test_encoding, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataLoader = DataLoader(full_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids  # True labels\n",
    "    preds = pred.predictions.argmax(-1)  # Predicted labels (argmax along the last axis)\n",
    "\n",
    "    # Using precision_recall_fscore_support to compute precision, recall, F1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "\n",
    "    # Using accuracy_score to compute accuracy\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Returning a dictionary containing the computed metrics\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./output', \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=100,              \n",
    "    per_device_train_batch_size=32,  \n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,                \n",
    "    weight_decay=0.05,\n",
    "    logging_strategy='steps',\n",
    "    logging_dir='./logs',            \n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\", \n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataloader,         \n",
    "    eval_dataset=test_dataloader,            \n",
    "    compute_metrics= compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f16f94e268e482db8156e4fda8f98c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2895, 'grad_norm': 6.290635585784912, 'learning_rate': 2.5e-05, 'epoch': 6.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed88a9946b0c4f9fbd71d3cd41443b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4870944023132324, 'eval_Accuracy': 0.43902439024390244, 'eval_F1': 0.10977413665585709, 'eval_Precision': 0.11655145929339479, 'eval_Recall': 0.13978494623655913, 'eval_runtime': 1.2433, 'eval_samples_per_second': 65.955, 'eval_steps_per_second': 4.826, 'epoch': 6.25}\n",
      "{'loss': 1.6858, 'grad_norm': 3.3381083011627197, 'learning_rate': 5e-05, 'epoch': 12.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e08f74e9591434f9f21d1c953e9cf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2049498558044434, 'eval_Accuracy': 0.7560975609756098, 'eval_F1': 0.4643578643578643, 'eval_Precision': 0.452020202020202, 'eval_Recall': 0.48484848484848486, 'eval_runtime': 0.2927, 'eval_samples_per_second': 280.135, 'eval_steps_per_second': 20.498, 'epoch': 12.5}\n",
      "{'loss': 0.6521, 'grad_norm': 1.7712889909744263, 'learning_rate': 4.642857142857143e-05, 'epoch': 18.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae8ed1c3bd1437a900854347982f584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmoses/miniconda3/envs/mconda38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5323908925056458, 'eval_Accuracy': 0.9878048780487805, 'eval_F1': 0.9615384615384616, 'eval_Precision': 0.9591836734693878, 'eval_Recall': 0.9642857142857143, 'eval_runtime': 0.3197, 'eval_samples_per_second': 256.496, 'eval_steps_per_second': 18.768, 'epoch': 18.75}\n",
      "{'loss': 0.2315, 'grad_norm': 0.9312476515769958, 'learning_rate': 4.2857142857142856e-05, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8559332bebc8453ea329a065215f4aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21531929075717926, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2887, 'eval_samples_per_second': 284.067, 'eval_steps_per_second': 20.785, 'epoch': 25.0}\n",
      "{'loss': 0.0918, 'grad_norm': 0.3334563076496124, 'learning_rate': 3.928571428571429e-05, 'epoch': 31.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79184602bf6b44f4a1bb5dcfaeb15056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07996250689029694, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2798, 'eval_samples_per_second': 293.1, 'eval_steps_per_second': 21.446, 'epoch': 31.25}\n",
      "{'loss': 0.0465, 'grad_norm': 0.211528018116951, 'learning_rate': 3.571428571428572e-05, 'epoch': 37.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be969671b54e47aca5454c97c61cd7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04615364596247673, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2704, 'eval_samples_per_second': 303.225, 'eval_steps_per_second': 22.187, 'epoch': 37.5}\n",
      "{'loss': 0.0311, 'grad_norm': 0.16053956747055054, 'learning_rate': 3.2142857142857144e-05, 'epoch': 43.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbf4e19691043fba3d0134d67bc7c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03280305489897728, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2819, 'eval_samples_per_second': 290.843, 'eval_steps_per_second': 21.281, 'epoch': 43.75}\n",
      "{'loss': 0.0244, 'grad_norm': 0.2031094878911972, 'learning_rate': 2.857142857142857e-05, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d6a32226cc41fa830e51ae01c537a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02576862834393978, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2828, 'eval_samples_per_second': 289.989, 'eval_steps_per_second': 21.219, 'epoch': 50.0}\n",
      "{'loss': 0.0199, 'grad_norm': 0.1286749243736267, 'learning_rate': 2.5e-05, 'epoch': 56.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb385b6c9cf441059a7c29159b27e92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0211139228194952, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2784, 'eval_samples_per_second': 294.588, 'eval_steps_per_second': 21.555, 'epoch': 56.25}\n",
      "{'loss': 0.017, 'grad_norm': 0.09523440152406693, 'learning_rate': 2.1428571428571428e-05, 'epoch': 62.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b122e35e2d4ccbaa09c183f44eafb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018190089613199234, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2873, 'eval_samples_per_second': 285.373, 'eval_steps_per_second': 20.881, 'epoch': 62.5}\n",
      "{'loss': 0.0152, 'grad_norm': 0.11290749907493591, 'learning_rate': 1.785714285714286e-05, 'epoch': 68.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cabed2c64044d5a928cfd0bd4ae6d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016140209510922432, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2934, 'eval_samples_per_second': 279.459, 'eval_steps_per_second': 20.448, 'epoch': 68.75}\n",
      "{'loss': 0.0135, 'grad_norm': 0.10391589254140854, 'learning_rate': 1.4285714285714285e-05, 'epoch': 75.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b33e8b9d64adba06f4a2071a0dac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014780910685658455, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.294, 'eval_samples_per_second': 278.916, 'eval_steps_per_second': 20.409, 'epoch': 75.0}\n",
      "{'loss': 0.0128, 'grad_norm': 0.0917266309261322, 'learning_rate': 1.0714285714285714e-05, 'epoch': 81.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3132cce026c24d5db35aaf5f05f22be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013751944527029991, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2724, 'eval_samples_per_second': 300.985, 'eval_steps_per_second': 22.023, 'epoch': 81.25}\n",
      "{'loss': 0.0121, 'grad_norm': 0.07534883916378021, 'learning_rate': 7.142857142857143e-06, 'epoch': 87.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16304aa322d44a3d96d0a763fe0b34f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013061584904789925, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2748, 'eval_samples_per_second': 298.422, 'eval_steps_per_second': 21.836, 'epoch': 87.5}\n",
      "{'loss': 0.0114, 'grad_norm': 0.08161803334951401, 'learning_rate': 3.5714285714285714e-06, 'epoch': 93.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493ddad04fd2409d9ff7db3ab7d5287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012680296786129475, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2863, 'eval_samples_per_second': 286.42, 'eval_steps_per_second': 20.958, 'epoch': 93.75}\n",
      "{'loss': 0.0112, 'grad_norm': 0.06197451055049896, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173dbd0381a547589351458b8ef8957f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012555195018649101, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 0.2736, 'eval_samples_per_second': 299.689, 'eval_steps_per_second': 21.928, 'epoch': 100.0}\n",
      "{'train_runtime': 311.8438, 'train_samples_per_second': 78.565, 'train_steps_per_second': 2.565, 'train_loss': 0.38535389192402364, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=0.38535389192402364, metrics={'train_runtime': 311.8438, 'train_samples_per_second': 78.565, 'train_steps_per_second': 2.565, 'total_flos': 214103859186000.0, 'train_loss': 0.38535389192402364, 'epoch': 100.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f62325523ff4c8cb6e85f22b0379b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7906ff089e5d46b48b7478eec29a280e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_Accuracy</th>\n",
       "      <th>eval_F1</th>\n",
       "      <th>eval_Precision</th>\n",
       "      <th>eval_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.008246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.012555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eval_loss  eval_Accuracy  eval_F1  eval_Precision  eval_Recall\n",
       "train   0.008246            1.0      1.0             1.0          1.0\n",
       "test    0.012555            1.0      1.0             1.0          1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=[trainer.evaluate(eval_dataset=df2) for df2 in [train_dataloader, test_dataloader]]\n",
    "pd.DataFrame(q, index=[\"train\",\"test\"]).iloc[:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"bert-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-model/tokenizer_config.json',\n",
       " 'bert-model/special_tokens_map.json',\n",
       " 'bert-model/vocab.txt',\n",
       " 'bert-model/added_tokens.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "new_tokenizer= BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= pipeline(\"sentiment-analysis\", model=new_model, tokenizer=new_tokenizer, device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'greeting', 'score': 0.9989669322967529}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Tokenize the input text and convert it to PyTorch tensors\n",
    "    inputs = new_tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cpu\")\n",
    "\n",
    "    # Pass the input tensors through the model\n",
    "    outputs = new_model(**inputs)\n",
    "\n",
    "    # Softmax the output to get probabilities\n",
    "    probs = outputs[0].softmax(1)\n",
    "\n",
    "    # Get the predicted label index\n",
    "    pred_label_idx = probs.argmax()\n",
    "\n",
    "    # Convert the predicted label index to the actual label using model configuration\n",
    "    pred_label = new_model.config.id2label[pred_label_idx.item()]\n",
    "\n",
    "    return probs, pred_label_idx, pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[9.9897e-01, 4.0382e-05, 5.0594e-05, 2.0533e-05, 4.7807e-05, 1.3049e-05,\n",
       "          1.7133e-05, 2.4188e-05, 1.1959e-05, 2.3613e-05, 3.7294e-05, 3.9787e-05,\n",
       "          4.8652e-05, 4.1899e-05, 1.0683e-05, 3.7709e-05, 1.7957e-05, 2.8868e-05,\n",
       "          3.0518e-05, 2.7206e-05, 1.1888e-05, 3.5707e-05, 2.1373e-05, 1.7299e-05,\n",
       "          1.1532e-05, 1.4921e-05, 1.5354e-05, 5.2564e-05, 9.3532e-06, 1.2270e-05,\n",
       "          2.2896e-05, 4.4233e-05, 4.9501e-05, 2.9216e-05, 4.3846e-05, 3.2940e-05,\n",
       "          2.5992e-05, 1.2399e-05]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor(0),\n",
       " 'greeting')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello\"\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(pipe):\n",
    "    \n",
    "    print(\"CHATBOT: Hi! I am your virtual assistance,Feel free to ask, and I'll do my best to provide you with answers and assistance..\")\n",
    "    print(\"Type 'quit' to exit the chat\\n\\n\")\n",
    "    \n",
    "    text = input(\"User: \").strip().lower()\n",
    "    \n",
    "    while(text != 'quit'):\n",
    "\n",
    "        score = pipe(text)[0]['score']\n",
    "        \n",
    "        if score < 0.8:\n",
    "            print(\"Chatbot: Sorry I can't answer that\\n\\n\")\n",
    "            text = input(\"User: \").strip().lower()\n",
    "            continue\n",
    "        \n",
    "        label = label2id[pipe(text)[0]['label']]\n",
    "        response = random.choice(intents['intents'][label]['responses'])\n",
    "        \n",
    "        print(f\"CHATBOT: {response}\\n\\n\")\n",
    "            \n",
    "        text = input(\"YOU: \").strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHATBOT: Hi! I am your virtual assistance,Feel free to ask, and I'll do my best to provide you with answers and assistance..\n",
      "Type 'quit' to exit the chat\n",
      "\n",
      "\n",
      "CHATBOT: How may I be of service to you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat(pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mconda38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
